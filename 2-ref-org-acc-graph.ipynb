{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Python\\aox\\enzyme-mining-aox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph includes the nodes reference literature (ref), organism (org) and enzyme sequence (accession) (acc) and the edges between them. Data sources included Brenda and UniProt, with the former providing mainly (ref, org) associations. The latter complements (ref, org) and provides information on (ref, acc) and (ref, org). The code here is used to generate data suitable for [CytoScape](https://cytoscape.org/) import, i.e. an `edge` table and a `node` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are based on the files generated by the `[5-7]-[ref/seq/org]-annotation.ipynb` scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = os.path.join(CURRENT_DIR, \"data\", \"aox\")\n",
    "GRAPHDIR = os.path.join(DATADIR, \"graph\", \"ref_org_acc\")\n",
    "\n",
    "filenames = {\n",
    "    # download or curate from the database website\n",
    "    \"brenda_ref_organism\": join(DATADIR, \"raw\", \"brenda_ref_organism.txt\"), # the publiaction list from brenda (the brenda-reference ID)\n",
    "    \"pubmed_ref_organism\": join(DATADIR, \"raw\", \"pubmed_ref_organism.txt\"), # the publication list from uniprot (the pubmed id)\n",
    "    \"pubmed_ref_sequence\": join(DATADIR, \"raw\", \"pubmed_ref_sequence.txt\"), # the sequence list from uniprot (the uniprot accession)\n",
    "    \"brenda_reference\": join(DATADIR, \"raw\", \"brenda_reference.tsv\"),\n",
    "    \"uniprot_sequence\": join(DATADIR, \"raw\", \"uniprot_sequence.tsv\"),\n",
    "\n",
    "    # results\n",
    "    \"edge\": join(GRAPHDIR, \"edges.tsv\"),\n",
    "    \"node\": join(GRAPHDIR, \"nodes.tsv\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_split(str_orgs):\n",
    "    orgs = []\n",
    "    str_orgs = str_orgs.strip().replace('[','').replace(']','')\n",
    "    for str_org in str_orgs.split(','):\n",
    "        s = str_org.strip().split(' ')\n",
    "        if len(s) >= 2:\n",
    "            orgs.append(f\"{s[0]} {s[1]}\")\n",
    "    return orgs\n",
    "\n",
    "def refs_split(str_refs):\n",
    "    ref = []\n",
    "    if isinstance(str_refs, str):\n",
    "        ref = [ int(i.strip()) for i in str_refs.split(';')]\n",
    "    else:\n",
    "        if not np.isnan(str_refs):\n",
    "            ref = [int(str_refs)]\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edge(ref, org): 117 (Adding Brenda)\n",
      "Number of edge(ref, org): 135 (Adding UniProt)\n",
      "Number of edge(ref, seq): 16 (Adding UniProt)\n",
      "Number of edge(seq, org): 104 (Adding UniProt)\n"
     ]
    }
   ],
   "source": [
    "edge_reference_organism = set()\n",
    "edge_reference_accession = set()\n",
    "edge_accession_organism = set()\n",
    "\n",
    "# make the edge between reference and organism (from brenda)\n",
    "with open(filenames['brenda_ref_organism'], \"r\") as f:\n",
    "    brenda_ref_organism = f.read().split('\\n')\n",
    "brenda_ref_organism = set([int(i) for i in brenda_ref_organism])\n",
    "\n",
    "ec_reference = pd.read_csv(filenames['brenda_reference'], sep='\\t')\n",
    "ec_reference.rename(columns={\n",
    "    col: col.strip() for col in ec_reference.columns\n",
    "}, inplace=True)\n",
    "\n",
    "for ref, orgs, pid in zip(ec_reference['REF'], ec_reference['ORGANISM (UNIPROT)'], ec_reference['PUBMED ID']):\n",
    "    if ref in brenda_ref_organism:\n",
    "        for org in org_split(orgs):\n",
    "            pre = f\"Brenda{ref}\"\n",
    "            edge_reference_organism.add((pre, org))\n",
    "            # print(pre, org)\n",
    "\n",
    "print(f\"Number of edge(ref, org): {len(edge_reference_organism)} (Adding Brenda)\")\n",
    "\n",
    "# make the edge between reference and organism (from uniprot)\n",
    "with open(filenames['pubmed_ref_organism'], \"r\") as f:\n",
    "    pubmed_ref_organism = f.read().split('\\n')\n",
    "pubmed_ref_organism = set([int(i) for i in pubmed_ref_organism])\n",
    "\n",
    "uniprot_ec = pd.read_csv(filenames['uniprot_sequence'], sep=\"\\t\")\n",
    "for refs, orgs in zip(uniprot_ec['PubMed ID'], uniprot_ec['Organism']):\n",
    "    for ref in refs_split(refs):\n",
    "        if ref in pubmed_ref_organism:\n",
    "            for org in org_split(orgs):\n",
    "                pre = f\"Pubmed{ref}\"\n",
    "                edge_reference_organism.add((pre, org))\n",
    "\n",
    "print(f\"Number of edge(ref, org): {len(edge_reference_organism)} (Adding UniProt)\")\n",
    "\n",
    "# make the edge between reference and accession (sequence) (from uniprot)\n",
    "with open(filenames['pubmed_ref_sequence'], \"r\") as f:\n",
    "    pubmed_ref_sequence = f.read().split('\\n')\n",
    "pubmed_ref_sequence = set([int(i) for i in pubmed_ref_sequence])\n",
    "\n",
    "for refs, accession in zip(uniprot_ec['PubMed ID'], uniprot_ec['Entry Name']):\n",
    "    for ref in refs_split(refs):\n",
    "        if ref in pubmed_ref_sequence:\n",
    "            pre = f\"Pubmed{ref}\"\n",
    "            edge_reference_accession.add((pre, accession))\n",
    "            # print(pre, accession)\n",
    "\n",
    "print(f\"Number of edge(ref, seq): {len(edge_reference_accession)} (Adding UniProt)\")\n",
    "\n",
    "\n",
    "# make the edge between accession and organism (from uniprot)\n",
    "for orgs, accession in zip(uniprot_ec['Organism'], uniprot_ec['Entry Name']):\n",
    "    for org in org_split(orgs):\n",
    "        edge_accession_organism.add((accession, org))\n",
    "        # print(org, accession)\n",
    "print(f\"Number of edge(seq, org): {len(edge_accession_organism)} (Adding UniProt)\")\n",
    "\n",
    "\n",
    "# output the edges to file\n",
    "edges = pd.concat([\n",
    "    pd.DataFrame(edge_reference_organism),\n",
    "    pd.DataFrame(edge_reference_accession),\n",
    "    pd.DataFrame(edge_accession_organism),\n",
    "])\n",
    "\n",
    "edges.to_csv(filenames['edge'], sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = \"1.1.3.13\"\n",
    "urls = {\n",
    "    \"brenda\": f\"https://www.brenda-enzymes.org/literature.php?e={ec}\" + \"&r={}\",\n",
    "    \"pubmed\": \"https://pubmed.ncbi.nlm.nih.gov/{}/\",\n",
    "    \"uniprot\": \"https://www.uniprot.org/uniprotkb/{}/entry\",\n",
    "    \"ncbi_taxonomy\": \"https://www.ncbi.nlm.nih.gov/taxonomy/?term={}\"\n",
    "}\n",
    "def make_url(_id:str, _type:str):\n",
    "    if _type == \"reference\":\n",
    "        if _id.startswith(\"Pubmed\"):\n",
    "            url = urls['pubmed'].format(_id[6:])\n",
    "        elif _id.startswith(\"Brenda\"):\n",
    "            url = urls['brenda'].format(_id[6:])\n",
    "    elif _type == \"organism\":\n",
    "        url = urls['ncbi_taxonomy'].format(_id)\n",
    "    elif _type == \"accession\":\n",
    "        url = urls['uniprot'].format(_id)\n",
    "    else:\n",
    "        url = f\"https://cn.bing.com/search?q={_id}+{_type}\"\n",
    "    url = url.replace(\" \", \"+\")\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the nodes\n",
    "# using the set to \n",
    "node_reference = set()\n",
    "node_organism = set()\n",
    "node_accession = set()\n",
    "\n",
    "for r,o in edge_reference_organism:\n",
    "    node_reference.add((r, \"reference\", make_url(r, \"reference\")))\n",
    "    node_organism.add((o, \"organism\", make_url(o, \"organism\")))\n",
    "for r,a in edge_reference_accession:\n",
    "    node_reference.add((r, \"reference\", make_url(r, \"reference\")))\n",
    "    node_accession.add((a, \"accession\", make_url(a, \"accession\")))\n",
    "for a, o in edge_accession_organism:\n",
    "    node_organism.add((o, \"organism\", make_url(o, \"organism\")))\n",
    "    node_accession.add((a, \"accession\", make_url(a, \"accession\")))\n",
    "\n",
    "\n",
    "# output the nodes to file\n",
    "df_node_reference = pd.DataFrame(node_reference, columns = [\"name\", \"type\", \"url\"])\n",
    "df_node_reference['representation'] = df_node_reference.index\n",
    "\n",
    "df_node_organism = pd.DataFrame(node_organism, columns = [\"name\", \"type\", \"url\"])\n",
    "df_node_organism['representation'] = df_node_organism.index\n",
    "\n",
    "df_node_accession = pd.DataFrame(node_accession, columns = [\"name\", \"type\", \"url\"])\n",
    "df_node_accession['representation'] = df_node_accession.index\n",
    "\n",
    "nodes = pd.concat([\n",
    "    df_node_reference,\n",
    "    df_node_organism,\n",
    "    df_node_accession\n",
    "])\n",
    "nodes.to_csv(filenames['node'], sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enzyme_mining38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
